Setting UP A Data Pipeline to test conversation generation and to generate QA pairs for fine tuning a model
  I am working on fine-tuning a small model that can run on a 2060 GPU until I get 96GB 5090 MSI
  I want to do this all free and that is my goal
  This is all experimental so use at your own risk

###PURPOSE
  -I want to use small models because I find big models monolithic. Sure you get better results but you can get just as good results with embedding strategies, LoRA and quants
  -Just posting my learning experience for others who may be looking to do something like this

##WHAT YOU NEED
  Data. You can use Huggingface or Kaggle public datasets or you can generate your own synthetically to fine-tune.
  I am using Meta Synthetic Data Kit: https://github.com/meta-llama/synthetic-data-kit

##Requirements for synthetic data kit
  -Miniconda/conda or pure python
  -Local vLLM like Ollama or LM Studio or Api key for cloud LLM
  -Files to extract data

##WHAT NEXT
  -After installing the synthetic data kit feed it some documents. The instructions are pretty straightforward
  -Generate a mix of data. To fine-tune a model you should have repeats and atleast 2K data points. BE SURE TO CLEAN ANY PHI!
  -You need a set of COT and QA which you can even out but the synthetic kit will include both when you curate it if you generated the cot 
  -Once data is saved, use an unsloth notebook that has already been created but tweaked. This can be done using a T4 free which are usually available over the weekends or after 5pm EST
  -What you are going to be doing is adding weights to the model of your choosing
  -Unsloth has some free collab notebooks but you just need to tweak them which I will upload at a later time

##FILES
  -JSON files are just example outputs feeding various documents to different models. You can play with the prompts in the yaml file to get it to 
  -config.yaml (just the settings which is using a LM Studio running locally)

##USEFULNESS
  -This has been very useful in testing how Agent 0 will respond to various scenarios and to check the quality of my data.
  -I am not 100% certain that a custom model is needed unless you want something very specific or if you want to create an adversary for hacking testing

##USE CASES
  -Have Agent Zero run the data pipeline itself?






